{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de Modelos de Redes Neuronales sobre Imágenes Termográficas para la Detección del Cáncer de Mama\n",
    "\n",
    "## Tesis de Maestría en Inteligencia Artificial Aplicada\n",
    "\n",
    "**Objetivo:** Evaluar modelos basados en redes neuronales profundas para la clasificación automática de imágenes termográficas en la detección temprana del cáncer de mama.\n",
    "\n",
    "**Metodología:** Feature Extraction con CNNs preentrenadas + Clasificador SVM\n",
    "- **Modelo 1:** EfficientNet-B0 (extractor) + SVM (clasificador)\n",
    "- **Modelo 2:** ResNet50 (extractor) + SVM (clasificador)\n",
    "\n",
    "**Dataset:** DMR-IR del Visual Lab UFF (272 imágenes: 177 healthy, 95 sick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuración del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones estándar\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Configurar warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Agregar directorio src al path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Verificar PyTorch y dispositivo\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS disponible: {torch.backends.mps.is_available()}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Configurar dispositivo\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"Usando MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(f\"Usando CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"Usando CPU\")\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar módulos del proyecto\n",
    "from src import preprocessing, feature_extraction, models, evaluation, visualization\n",
    "\n",
    "# Recargar módulos en caso de modificaciones\n",
    "from importlib import reload\n",
    "reload(preprocessing)\n",
    "reload(feature_extraction)\n",
    "reload(models)\n",
    "reload(evaluation)\n",
    "reload(visualization)\n",
    "\n",
    "print(\"Módulos cargados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de rutas\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data' / 'raw'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "MODELS_DIR = RESULTS_DIR / 'models'\n",
    "METRICS_DIR = RESULTS_DIR / 'metrics'\n",
    "FEATURES_DIR = RESULTS_DIR / 'features'\n",
    "\n",
    "# Crear directorios si no existen\n",
    "for directory in [FIGURES_DIR, MODELS_DIR, METRICS_DIR, FEATURES_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directorio del proyecto: {PROJECT_ROOT}\")\n",
    "print(f\"Directorio de datos: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Configuración del Dataset\n",
    "\n",
    "**IMPORTANTE:** Configura la ruta a tu dataset DMR-IR en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURA AQUÍ LA RUTA A TU DATASET\n",
    "# ============================================\n",
    "# El dataset debe tener la estructura:\n",
    "# DMR-IR/\n",
    "# ├── healthy/\n",
    "# │   ├── imagen1.png\n",
    "# │   └── ...\n",
    "# └── sick/\n",
    "#     ├── imagen1.png\n",
    "#     └── ...\n",
    "\n",
    "# Opción 1: Ruta absoluta\n",
    "# DATASET_PATH = Path(\"/ruta/completa/a/DMR-IR\")\n",
    "\n",
    "# Opción 2: Copiar dataset a data/raw/DMR-IR\n",
    "DATASET_PATH = DATA_DIR / 'DMR-IR'\n",
    "\n",
    "# Verificar existencia\n",
    "if not DATASET_PATH.exists():\n",
    "    print(f\"⚠️  ADVERTENCIA: El dataset no se encontró en: {DATASET_PATH}\")\n",
    "    print(\"\\nPor favor:\")\n",
    "    print(\"1. Copia el dataset DMR-IR a la carpeta 'data/raw/'\")\n",
    "    print(\"2. O modifica DATASET_PATH con la ruta correcta\")\n",
    "else:\n",
    "    print(f\"✓ Dataset encontrado en: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener información del dataset\n",
    "dataset_info = preprocessing.get_dataset_info(DATASET_PATH)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"INFORMACIÓN DEL DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total de imágenes: {dataset_info['total_count']}\")\n",
    "print(f\"  - Healthy (sanas): {dataset_info['healthy_count']}\")\n",
    "print(f\"  - Sick (enfermas): {dataset_info['sick_count']}\")\n",
    "print(f\"\\nRatio de desbalance: {dataset_info['healthy_count']/dataset_info['sick_count']:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Carga y Preprocesamiento del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y preprocesar todas las imágenes\n",
    "# Este proceso aplica:\n",
    "# 1. CLAHE para normalización de contraste\n",
    "# 2. Redimensionado a 224x224\n",
    "# 3. Normalización ImageNet\n",
    "\n",
    "print(\"Cargando y preprocesando imágenes...\")\n",
    "print(\"(Este proceso puede tardar unos minutos)\\n\")\n",
    "\n",
    "images, labels, paths = preprocessing.load_dataset(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    apply_clahe_norm=True,\n",
    "    normalize_imagenet=True\n",
    ")\n",
    "\n",
    "print(f\"\\nImágenes cargadas: {images.shape}\")\n",
    "print(f\"Labels: {labels.shape}\")\n",
    "print(f\"Distribución: Healthy={sum(labels==0)}, Sick={sum(labels==1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribución de clases\n",
    "fig = visualization.plot_class_distribution(\n",
    "    labels,\n",
    "    split_name=\"Complete Dataset\",\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. División del Dataset (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División estratificada: 70% train, 15% validation, 15% test\n",
    "# CRÍTICO: La división se hace ANTES de cualquier augmentation\n",
    "\n",
    "splits = preprocessing.get_data_splits(\n",
    "    images, labels, paths,\n",
    "    test_size=0.30,  # 30% para val+test\n",
    "    val_ratio=0.50,  # 50% de ese 30% para test (15% del total)\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extraer los splits\n",
    "X_train = splits['X_train']\n",
    "X_val = splits['X_val']\n",
    "X_test = splits['X_test']\n",
    "y_train = splits['y_train']\n",
    "y_val = splits['y_val']\n",
    "y_test = splits['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribución en cada split\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, (name, y) in zip(axes, [('Train', y_train), ('Validation', y_val), ('Test', y_test)]):\n",
    "    counts = [sum(y == 0), sum(y == 1)]\n",
    "    bars = ax.bar(['Healthy', 'Sick'], counts, color=['#27ae60', '#e74c3c'])\n",
    "    ax.set_title(f'{name} Set (n={len(y)})')\n",
    "    ax.set_ylabel('Count')\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax.annotate(f'{count}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                   xytext=(0, 3), textcoords='offset points', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'dataset_splits_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Visualización de Ejemplos de Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar algunas imágenes sin preprocesamiento para comparación\n",
    "import cv2\n",
    "\n",
    "# Seleccionar ejemplos (2 healthy, 2 sick)\n",
    "example_indices = [\n",
    "    np.where(labels == 0)[0][0],  # Primera healthy\n",
    "    np.where(labels == 0)[0][1],  # Segunda healthy\n",
    "    np.where(labels == 1)[0][0],  # Primera sick\n",
    "    np.where(labels == 1)[0][1],  # Segunda sick\n",
    "]\n",
    "\n",
    "original_images = []\n",
    "for idx in example_indices:\n",
    "    img = cv2.imread(paths[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    original_images.append(img.astype(np.float32) / 255.0)\n",
    "\n",
    "processed_images = [images[idx] for idx in example_indices]\n",
    "example_labels = [labels[idx] for idx in example_indices]\n",
    "\n",
    "# Visualizar\n",
    "fig = visualization.plot_preprocessing_examples(\n",
    "    original_images,\n",
    "    processed_images,\n",
    "    example_labels,\n",
    "    n_examples=4,\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Extracción de Características con EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXTRACCIÓN DE CARACTERÍSTICAS CON EFFICIENTNET-B0\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extraer features del conjunto de entrenamiento (con augmentation)\n",
    "print(\"\\n[1/3] Extrayendo features de entrenamiento (con augmentation)...\")\n",
    "features_train_effnet, labels_train_aug = feature_extraction.extract_features_with_augmentation(\n",
    "    X_train, y_train,\n",
    "    model_name='efficientnet_b0',\n",
    "    device=DEVICE,\n",
    "    batch_size=32,\n",
    "    num_augmentations=5\n",
    ")\n",
    "\n",
    "# Extraer features de validación (sin augmentation)\n",
    "print(\"\\n[2/3] Extrayendo features de validación...\")\n",
    "features_val_effnet = feature_extraction.extract_features_simple(\n",
    "    X_val,\n",
    "    model_name='efficientnet_b0',\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Extraer features de test (sin augmentation)\n",
    "print(\"\\n[3/3] Extrayendo features de test...\")\n",
    "features_test_effnet = feature_extraction.extract_features_simple(\n",
    "    X_test,\n",
    "    model_name='efficientnet_b0',\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures extraídas:\")\n",
    "print(f\"  Train: {features_train_effnet.shape}\")\n",
    "print(f\"  Val:   {features_val_effnet.shape}\")\n",
    "print(f\"  Test:  {features_test_effnet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar features de EfficientNet\n",
    "np.save(FEATURES_DIR / 'efficientnet_features_train.npy', features_train_effnet)\n",
    "np.save(FEATURES_DIR / 'efficientnet_features_val.npy', features_val_effnet)\n",
    "np.save(FEATURES_DIR / 'efficientnet_features_test.npy', features_test_effnet)\n",
    "np.save(FEATURES_DIR / 'efficientnet_labels_train_aug.npy', labels_train_aug)\n",
    "print(\"Features de EfficientNet guardadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Entrenamiento de SVM con Features de EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ENTRENAMIENTO DE SVM CON FEATURES DE EFFICIENTNET-B0\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Entrenar SVM con búsqueda de hiperparámetros\n",
    "model_effnet_svm, best_params_effnet, cv_results_effnet = models.train_svm_classifier(\n",
    "    features_train_effnet,\n",
    "    labels_train_aug,\n",
    "    features_val_effnet,\n",
    "    y_val,\n",
    "    cv_folds=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nMejores hiperparámetros encontrados:\")\n",
    "for param, value in best_params_effnet.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en el conjunto de test\n",
    "print(\"\\nEvaluación en conjunto de TEST:\")\n",
    "metrics_effnet, y_pred_effnet, y_proba_effnet = evaluation.evaluate_model(\n",
    "    model_effnet_svm,\n",
    "    features_test_effnet,\n",
    "    y_test,\n",
    "    model_name=\"EfficientNet-B0 + SVM\"\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "models.save_model(\n",
    "    model_effnet_svm,\n",
    "    str(MODELS_DIR / 'efficientnet_svm.joblib'),\n",
    "    metadata={\n",
    "        'model_name': 'EfficientNet-B0 + SVM',\n",
    "        'best_params': best_params_effnet,\n",
    "        'metrics': metrics_effnet\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión para EfficientNet-B0 + SVM\n",
    "fig_cm_effnet = visualization.plot_confusion_matrix(\n",
    "    y_test, y_pred_effnet,\n",
    "    model_name=\"EfficientNet-B0 + SVM\",\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Extracción de Características con ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXTRACCIÓN DE CARACTERÍSTICAS CON RESNET50\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extraer features del conjunto de entrenamiento (con augmentation)\n",
    "print(\"\\n[1/3] Extrayendo features de entrenamiento (con augmentation)...\")\n",
    "features_train_resnet, labels_train_aug_resnet = feature_extraction.extract_features_with_augmentation(\n",
    "    X_train, y_train,\n",
    "    model_name='resnet50',\n",
    "    device=DEVICE,\n",
    "    batch_size=32,\n",
    "    num_augmentations=5\n",
    ")\n",
    "\n",
    "# Extraer features de validación (sin augmentation)\n",
    "print(\"\\n[2/3] Extrayendo features de validación...\")\n",
    "features_val_resnet = feature_extraction.extract_features_simple(\n",
    "    X_val,\n",
    "    model_name='resnet50',\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Extraer features de test (sin augmentation)\n",
    "print(\"\\n[3/3] Extrayendo features de test...\")\n",
    "features_test_resnet = feature_extraction.extract_features_simple(\n",
    "    X_test,\n",
    "    model_name='resnet50',\n",
    "    device=DEVICE,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures extraídas:\")\n",
    "print(f\"  Train: {features_train_resnet.shape}\")\n",
    "print(f\"  Val:   {features_val_resnet.shape}\")\n",
    "print(f\"  Test:  {features_test_resnet.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar features de ResNet\n",
    "np.save(FEATURES_DIR / 'resnet_features_train.npy', features_train_resnet)\n",
    "np.save(FEATURES_DIR / 'resnet_features_val.npy', features_val_resnet)\n",
    "np.save(FEATURES_DIR / 'resnet_features_test.npy', features_test_resnet)\n",
    "np.save(FEATURES_DIR / 'resnet_labels_train_aug.npy', labels_train_aug_resnet)\n",
    "print(\"Features de ResNet guardadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Entrenamiento de SVM con Features de ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ENTRENAMIENTO DE SVM CON FEATURES DE RESNET50\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Entrenar SVM con búsqueda de hiperparámetros\n",
    "model_resnet_svm, best_params_resnet, cv_results_resnet = models.train_svm_classifier(\n",
    "    features_train_resnet,\n",
    "    labels_train_aug_resnet,\n",
    "    features_val_resnet,\n",
    "    y_val,\n",
    "    cv_folds=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nMejores hiperparámetros encontrados:\")\n",
    "for param, value in best_params_resnet.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en el conjunto de test\n",
    "print(\"\\nEvaluación en conjunto de TEST:\")\n",
    "metrics_resnet, y_pred_resnet, y_proba_resnet = evaluation.evaluate_model(\n",
    "    model_resnet_svm,\n",
    "    features_test_resnet,\n",
    "    y_test,\n",
    "    model_name=\"ResNet50 + SVM\"\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "models.save_model(\n",
    "    model_resnet_svm,\n",
    "    str(MODELS_DIR / 'resnet_svm.joblib'),\n",
    "    metadata={\n",
    "        'model_name': 'ResNet50 + SVM',\n",
    "        'best_params': best_params_resnet,\n",
    "        'metrics': metrics_resnet\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión para ResNet50 + SVM\n",
    "fig_cm_resnet = visualization.plot_confusion_matrix(\n",
    "    y_test, y_pred_resnet,\n",
    "    model_name=\"ResNet50 + SVM\",\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para comparación\n",
    "all_metrics = {\n",
    "    'EfficientNet-B0 + SVM': metrics_effnet,\n",
    "    'ResNet50 + SVM': metrics_resnet\n",
    "}\n",
    "\n",
    "# Tabla comparativa\n",
    "print(\"=\"*70)\n",
    "print(\"TABLA COMPARATIVA DE RESULTADOS\")\n",
    "print(\"=\"*70)\n",
    "comparison_table = evaluation.compare_models(all_metrics)\n",
    "print(comparison_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación de métricas\n",
    "fig_metrics = visualization.plot_metrics_comparison(\n",
    "    all_metrics,\n",
    "    metrics_to_plot=['accuracy', 'precision', 'recall', 'specificity', 'f1_score'],\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC comparativas\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Calcular datos ROC\n",
    "fpr_effnet, tpr_effnet, _ = roc_curve(y_test, y_proba_effnet)\n",
    "auc_effnet = roc_auc_score(y_test, y_proba_effnet)\n",
    "\n",
    "fpr_resnet, tpr_resnet, _ = roc_curve(y_test, y_proba_resnet)\n",
    "auc_resnet = roc_auc_score(y_test, y_proba_resnet)\n",
    "\n",
    "roc_data = {\n",
    "    'EfficientNet-B0 + SVM': (fpr_effnet, tpr_effnet, auc_effnet),\n",
    "    'ResNet50 + SVM': (fpr_resnet, tpr_resnet, auc_resnet)\n",
    "}\n",
    "\n",
    "fig_roc = visualization.plot_roc_curves(\n",
    "    roc_data,\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Visualización de Distribución de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribución de features con t-SNE (EfficientNet)\n",
    "print(\"Generando visualización t-SNE para EfficientNet-B0...\")\n",
    "fig_tsne_effnet = visualization.plot_feature_distribution(\n",
    "    features_test_effnet,\n",
    "    y_test,\n",
    "    method='tsne',\n",
    "    model_name=\"EfficientNet-B0\",\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribución de features con t-SNE (ResNet)\n",
    "print(\"Generando visualización t-SNE para ResNet50...\")\n",
    "fig_tsne_resnet = visualization.plot_feature_distribution(\n",
    "    features_test_resnet,\n",
    "    y_test,\n",
    "    method='tsne',\n",
    "    model_name=\"ResNet50\",\n",
    "    output_dir=str(FIGURES_DIR)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Guardar Resultados Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar todas las métricas en JSON\n",
    "all_results = {\n",
    "    'efficientnet_b0_svm': {\n",
    "        'metrics': {k: float(v) if isinstance(v, (np.floating, np.integer)) else v \n",
    "                   for k, v in metrics_effnet.items()},\n",
    "        'best_params': best_params_effnet\n",
    "    },\n",
    "    'resnet50_svm': {\n",
    "        'metrics': {k: float(v) if isinstance(v, (np.floating, np.integer)) else v \n",
    "                   for k, v in metrics_resnet.items()},\n",
    "        'best_params': best_params_resnet\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(METRICS_DIR / 'comparison_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "print(f\"Resultados guardados en: {METRICS_DIR / 'comparison_results.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar labels de test para reproducibilidad\n",
    "np.save(FEATURES_DIR / 'y_test.npy', y_test)\n",
    "np.save(FEATURES_DIR / 'y_train.npy', y_train)\n",
    "np.save(FEATURES_DIR / 'y_val.npy', y_val)\n",
    "print(\"Labels guardadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar tabla LaTeX para la tesis\n",
    "latex_table = visualization.create_latex_table(\n",
    "    all_metrics,\n",
    "    caption=\"Comparación de resultados entre modelos de clasificación\",\n",
    "    label=\"tab:model_comparison\"\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TABLA LATEX PARA LA TESIS\")\n",
    "print(\"=\"*70)\n",
    "print(latex_table)\n",
    "\n",
    "# Guardar tabla LaTeX\n",
    "with open(METRICS_DIR / 'results_table.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "print(f\"\\nTabla guardada en: {METRICS_DIR / 'results_table.tex'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN FINAL DE EXPERIMENTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset: DMR-IR\")\n",
    "print(f\"Total de imágenes: {len(labels)}\")\n",
    "print(f\"  - Healthy: {sum(labels==0)}\")\n",
    "print(f\"  - Sick: {sum(labels==1)}\")\n",
    "\n",
    "print(f\"\\nDivisión del dataset:\")\n",
    "print(f\"  - Train: {len(y_train)} ({len(y_train)/len(labels)*100:.1f}%)\")\n",
    "print(f\"  - Validation: {len(y_val)} ({len(y_val)/len(labels)*100:.1f}%)\")\n",
    "print(f\"  - Test: {len(y_test)} ({len(y_test)/len(labels)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS EN CONJUNTO DE TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determinar mejor modelo\n",
    "best_model = 'EfficientNet-B0 + SVM' if metrics_effnet['f1_score'] > metrics_resnet['f1_score'] else 'ResNet50 + SVM'\n",
    "\n",
    "for model_name, metrics in all_metrics.items():\n",
    "    winner = \" ⭐ MEJOR\" if model_name == best_model else \"\"\n",
    "    print(f\"\\n{model_name}{winner}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Accuracy:    {metrics['accuracy']*100:.2f}%\")\n",
    "    print(f\"  Precision:   {metrics['precision']*100:.2f}%\")\n",
    "    print(f\"  Recall:      {metrics['recall']*100:.2f}%\")\n",
    "    print(f\"  Specificity: {metrics['specificity']*100:.2f}%\")\n",
    "    print(f\"  F1-Score:    {metrics['f1_score']*100:.2f}%\")\n",
    "    print(f\"  AUC-ROC:     {metrics['auc_roc']:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ARCHIVOS GENERADOS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFiguras: {FIGURES_DIR}\")\n",
    "print(f\"Modelos: {MODELS_DIR}\")\n",
    "print(f\"Métricas: {METRICS_DIR}\")\n",
    "print(f\"Features: {FEATURES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Conclusiones\n",
    "\n",
    "### Análisis de Resultados\n",
    "\n",
    "Basado en los experimentos realizados, podemos concluir:\n",
    "\n",
    "1. **Comparación de Arquitecturas:**\n",
    "   - [Completar basado en resultados]\n",
    "\n",
    "2. **Métricas Clínicas Relevantes:**\n",
    "   - **Recall (Sensibilidad):** Mide la capacidad de detectar pacientes enfermos. Crítico para no perder casos.\n",
    "   - **Specificity (Especificidad):** Mide la capacidad de identificar pacientes sanos. Reduce falsos positivos.\n",
    "\n",
    "3. **Recomendación:**\n",
    "   - [Completar basado en el mejor modelo]\n",
    "\n",
    "### Limitaciones\n",
    "- Dataset pequeño (272 imágenes)\n",
    "- Posible sesgo por paletas de color diferentes\n",
    "\n",
    "### Trabajo Futuro\n",
    "- Validación con datasets externos\n",
    "- Experimentar con fine-tuning de las CNNs\n",
    "- Implementar técnicas de explicabilidad (Grad-CAM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
